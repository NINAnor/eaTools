---
title: "Test ea_spread"
author: "Anders Kolstad"
date: "2023-01-19"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(tmap)
library(dplyr)

```

## Testing and developing ea_spread

```{r}
library(devtools)
load_all()
library(dplyr)
library(sf)
library(stars)
```


```{r}
ea_spread_dev <- function(indicator_data,
                      indicator,
                      regions,
                      groups,
                      threshold = 1,
                      summarise = FALSE){
  ID <- SHAPE <-area <- indicator_NA <- meanIndicatorValue <- w_mean <-  NULL
  if("sf" %in% class(indicator_data) & "sf" %in% class(regions)){
    # get the intersections
    st_agr(indicator_data) <- "constant"
    st_agr(regions) <- "constant"
    indicator_split <- sf::st_intersection(indicator_data, regions)
    # calculate area of the intersections
    indicator_split$area <- drop_units(sf::st_area(indicator_split))
  } else stop("The input data is not in a supported format. Both indicator_data and regions need to be sf objects.")
  # Calculate the area weighted mean indicator values for each region

  if(missing(indicator)) stop("Indicator column is not defined")
  if(missing(groups)) stop("Group is not defined")

  groups_int <- enquo(groups)
  indicator_int <- enquo(indicator)

  myMean <- function(data, i) {
    d2 <- data[i,]
    stats::weighted.mean(d2[,1], d2[,2], na.rm=T)
  }

  mySD <- function(.data){
    if (dplyr::is_grouped_df(.data)) {
      return(dplyr::do(.data, mySD(.)))}
    newx <- .data %>%
      as.data.frame() %>%
      dplyr::select(!!indicator_int, area) %>%
      boot(myMean, R = 1000)
    as_tibble(sd(newx$t))
  }

  addSD <- indicator_split %>%
    group_by(!!groups_int) %>%
    mySD() %>%
    mutate("ID" = !!groups_int) %>%
    ungroup() %>%
    dplyr::select(all_of(c("ID", sd = "value")))

  summary_output <- indicator_split %>%
    group_by(!!groups_int) %>%
    mutate(n = n(),
           indicator_NA = ifelse(n >=threshold, !!indicator_int, NA))%>%
    summarise(total_area = sum(area),
              n = n(),
              w_mean = stats::weighted.mean(x = indicator_NA, w = area, na.rm=TRUE),
              mean = mean(indicator_NA, na.rm=TRUE)) %>%
    mutate("ID" = !!groups_int) %>%
    as.data.frame() %>%
    dplyr::select(-any_of(c("SHAPE", "geometry"))) %>%
    left_join(addSD, by = "ID") %>%
    mutate(sd = replace(sd, is.na(w_mean), NA))

  if(summarise == FALSE){
    # paste these new values into the regions data set
    regions <- regions %>%
      mutate("ID" = !!groups_int) %>%
      left_join(summary_output, by = "ID") %>%
      select(ID, w_mean, sd)
    return(regions)
  } else {
    summary_output %>%
      dplyr::select(-ID)
  }
}
```

```{r}
data("ex_polygons")
data("ex_raster")
```

## Example 1: Aggregate and spread to raster
Example using a raster to define homogeneous area classes.
Zooming in on the example data

```{r}
ex_raster_zoom <- ex_raster[,5:6, 28:29]
ex_polygons_zoom <- sf::st_crop(ex_polygons, ex_raster_zoom)
```

Scale the indicator
```{r}
ex_polygons_zoom$indicator <- ea_normalise(ex_polygons_zoom,
"condition_variable_2",
upper_reference_level = 7)

```

Tweak the data slightly for exaggerated effect
```{r}
ex_polygons_zoom$indicator[2:6] <- 1
```

Process the `ex_raster_zoom` (vectorose it) and define homogeneous areas based on the cell values.
```{r}
myRegions <- ea_homogeneous_area(ex_raster_zoom,
                                 groups = values)
```

Now use the function
```{r}
out1 <- ea_spread_dev(indicator_data = ex_polygons_zoom,
                 indicator = indicator,
                 regions = myRegions,
                 groups = values)

out1.2 <- ea_spread(indicator_data = ex_polygons_zoom,
                 indicator = indicator,
                 regions = myRegions,
                 groups = values)
```

... and plot the results
```{r}
plot(out1[,2])
```

## Example 2: Simple summary

```{r}
ea_spread_dev(indicator_data = ex_polygons_zoom,
                 indicator = indicator,
                 regions = myRegions,
                 groups = values,
                 summarise = T,
              threshold = 4)
```

What if some groups had no data
```{r}

myJoin <- sf::st_intersection(ex_polygons_zoom, myRegions)
# find those in class 3
myJoin$ID[myJoin$values == 3]

```
```{r}
toRemove <- c("NINFP2110040522", "NINFP2110034537", "NINFP2110034539")
```

```{r}
'%!in%' <- Negate('%in%')
```

```{r}
ea_spread_dev(indicator_data = ex_polygons_zoom[ex_polygons_zoom$ID %!in% toRemove,],
                 indicator = indicator,
                 regions = myRegions,
                 groups = values,
                 summarise = T)
```

It still works

# Example 3: Large rasters

Calculating the intersections of very large vector data sets takes a long time. For these cases it is easier to use raster calculations. 

Scale the indicator
```{r}
ex_polygons$indicator <- ea_normalise(ex_polygons,
                                      "condition_variable_2",
                                      upper_reference_level = 7)

```

```{r}
st_crs(ex_raster)==st_crs(ex_polygons)
```
If I wanted to rasterize the indicator, this is how. But I don't think I'll need to.
```{r, warning=T}
grd = st_as_stars(st_bbox(ex_polygons), dx = 50, dy = 50, values = NA_real_)

ex_polygons <- sf::st_set_crs(ex_polygons, 25833)
ex_polygons_rasterised <- st_rasterize(ex_polygons["indicator"],
                                       template = grd)
```

```{r}
tmap_mode("view")
tm_shape(ex_polygons_rasterised)+
  tm_raster(col = "indicator")+
tm_shape(ex_polygons)+
  tm_polygons(col="indicator", alpha=0.2)+
tm_layout(legend.outside = T)
```

Then I can share information between the rasters (somehow). TBC.


# Example 5: Point sampling polygons data set
We can also take a representative sample of points from a larger vector data set, and extract the indicator values for those points. 
The benefit is that points are much faster to work with.
```{r}
rSample <- st_sample(ex_polygons, size = 1000)
rSample_s <- st_sample(ex_polygons, size = 100)

```

```{r}
rSample2 <- st_extract(ex_raster, rSample)
```


```{r}
tmap_mode("view")
tm_shape(ex_raster)+
  tm_raster(alpha=.3)+
tm_shape(rSample2)+
  tm_dots(col = "values")+
  tm_layout(legend.outside = T)
```

The values do not match perfectly, but that's just a live transformation thing that has to do with the view mode
This static map is accurate.
```{r}
tmap_mode("plot")
tm_shape(ex_raster[,5:10, 5:10])+
  tm_raster(alpha=.3)+
tm_shape(rSample2)+
  tm_symbols(col = "values",
          size=1)+
  tm_layout(legend.outside = T)
```

I can also extract values from vector data sets
```{r}
ex_raster_vect <- st_as_sf(ex_raster)
rSample3 <- sf::st_intersection(ex_raster_vect, rSample_s)
```

```{r}
tm_shape(ex_raster_vect)+
  tm_polygons(col = "values", alpha=.8)+
tm_shape(rSample3)+
  tm_dots(col="values")+
tm_layout(legend.outside = T)
```

This is a perfect fit.








































